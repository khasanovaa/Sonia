{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !\"{sys.executable}\" -m pip install mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from numpy import random\n",
    "from mido import MidiTrack\n",
    "from mido import MidiFile, MetaMessage\n",
    "st = 0.0013354687499999999 * 3\n",
    "SOS_token = 0\n",
    "hid_size = 512\n",
    "time_cl = [0, 1, 2, 3, 5, 7, 11, 15, 20, 23, 35, 80, 122, 187]\n",
    "vel_cl = [0, 15, 33, 64, 80, 104, 125]\n",
    "tempo = 2000000\n",
    "note_cl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(events):\n",
    "    ans = []\n",
    "#     print(events)\n",
    "    for event in events:\n",
    "        if (event[0] == 'v'):\n",
    "            ans.append(event[1])\n",
    "        if (event[0] == 't'):\n",
    "            ans.append(len(vel_cl) + event[1])\n",
    "        if (event[0] == 'no'):\n",
    "            ans.append(len(vel_cl) + len(time_cl) + event[1])\n",
    "        if (event[0] == 'nof'):\n",
    "            ans.append(len(vel_cl) + len(time_cl) + len(note_cl) + event[1])\n",
    "    return ans\n",
    "\n",
    "def decoding(ans):\n",
    "    events = []\n",
    "    for n in ans:\n",
    "#         print(ans)\n",
    "        if (n < len(vel_cl)):\n",
    "            events.append(['v', n])\n",
    "        elif (n < len(vel_cl) + len(time_cl)):\n",
    "            events.append(['t', n - len(vel_cl)])\n",
    "        elif (n < len(vel_cl) + len(time_cl) + len(note_cl)):\n",
    "            events.append(['no', n - len(vel_cl) - len(time_cl)])\n",
    "        else:\n",
    "            events.append(['nof', n - len(vel_cl) - len(time_cl) - len(note_cl)])\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "velocityes = {}\n",
    "times = {}\n",
    "notes = {}\n",
    "def preprocess(path):\n",
    "    global count\n",
    "    global times, velcityes, notes, note_cl\n",
    "    mid = MidiFile('midi/'+path)    \n",
    "    messages = []\n",
    "    time = 0\n",
    "    vel = 0\n",
    "\n",
    "    for msg in mid:\n",
    "        if (msg.type == 'note_off' or msg.type == 'note_on'):\n",
    "            msg.time = int(msg.time/st)\n",
    "#             if (1):\n",
    "#                 if(msg.velocity in velocityes):\n",
    "#                     velocityes[msg.velocity] += 1\n",
    "#                 else:\n",
    "#                     velocityes[msg.velocity] = 1\n",
    "#                 if(msg.time in times):\n",
    "#                     times[msg.time] += 1\n",
    "#                 else:\n",
    "#                     times[msg.time] = 1\n",
    "#                 if(msg.note in notes):\n",
    "#                     notes[msg.note] += 1\n",
    "#                 else:\n",
    "#                     notes[msg.note] = 1\n",
    "            messages.append(msg)\n",
    "#             time = max(time, msg.time)\n",
    "#             vel = max(vel, msg.velocity)\n",
    "    for msg in messages:\n",
    "        if (msg.note not in note_cl):\n",
    "            note_cl.append(msg.note)\n",
    "        msg.note = note_cl.index(msg.note)\n",
    "        vel = msg.velocity\n",
    "        new_vel = 0\n",
    "        for i in range(len(vel_cl)):\n",
    "            if (abs(vel_cl[i] - vel) < abs(vel_cl[new_vel] - vel)):\n",
    "                new_vel = i\n",
    "        msg.velocity = new_vel\n",
    "    \n",
    "        time = msg.time\n",
    "        new_time = 0\n",
    "        for i in range(len(time_cl)):\n",
    "            if (abs(time_cl[i] - time) < abs(time_cl[new_time] - time)):\n",
    "                new_time = i\n",
    "        msg.time = new_time\n",
    "        \n",
    "    events = []    \n",
    "    last_vel = -1\n",
    "    last_time = -1\n",
    "    for msg in messages:\n",
    "        if (msg.velocity != last_vel):\n",
    "            last_vel = msg.velocity\n",
    "            events.append(['v', msg.velocity])\n",
    "        if (msg.time != last_time):\n",
    "            last_time = msg.time\n",
    "            events.append(['t', msg.time])\n",
    "        if (msg.type == 'note_on'):\n",
    "            events.append(['no', msg.note])\n",
    "        if (msg.type == 'note_off'):\n",
    "            events.append(['nof', msg.note])\n",
    "    \n",
    "    v = encoding(events)\n",
    "    return v\n",
    "\n",
    "def postprocess(v):\n",
    "    global count\n",
    "    d = decoding(v)\n",
    "    events = d\n",
    "    \n",
    "    \n",
    "    for i in range(len(events)):\n",
    "        event = events[i]\n",
    "        if (event[0] == 'v'):\n",
    "            event[1] = vel_cl[event[1]]\n",
    "        elif (event[0] == 't'):\n",
    "            event[1] = time_cl[event[1]]\n",
    "        else:\n",
    "            event[1] = note_cl[event[1]]\n",
    "    track = MidiTrack()\n",
    "    track.append(MetaMessage(\"set_tempo\", tempo=tempo, time=0))\n",
    "    velocity_n = 0\n",
    "    time_n = 0\n",
    "    for i in range(len(events)):\n",
    "        if (events[i][0] == 'v'):\n",
    "            velocity_n = events[i][1]\n",
    "        if (events[i][0] == 't'):\n",
    "            time_n = events[i][1]\n",
    "        if (events[i][0] == 'no'):\n",
    "            track.append(mido.Message('note_on', note=events[i][1], time=time_n, velocity=velocity_n))\n",
    "        if (events[i][0] == 'nof'):\n",
    "            track.append(mido.Message('note_off', note=events[i][1], time=time_n, velocity=velocity_n))\n",
    "    mid_f = MidiFile()\n",
    "    mid_f.tracks.append(track)\n",
    "    mid_f.save('midi_pr/new_song' + str(count) +'.mid')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = {}\n",
    "notes = {}\n",
    "count = 0\n",
    "songs = []\n",
    "velocityes = {}\n",
    "for path in os.listdir('midi'):\n",
    "    songs.append(preprocess(path))\n",
    "# for t in sorted(times):\n",
    "#     print(t, times[t])\n",
    "# for t in sorted(velocityes):\n",
    "#     print(t, velocityes[t])\n",
    "# for t in sorted(notes):\n",
    "#     if(notes[t] > 100):\n",
    "#         print(t, notes[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(target_tensor, decoder, decoder_optimizer, criterion, decoder_hidden):\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    target_length = target_tensor.size(2)//20\n",
    "    start = target_tensor.size(2) // 3\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "    print(target_length)\n",
    "    for di in range(start, target_length + start):\n",
    "#         print(di)\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        loss += criterion(decoder_output, target_tensor[0,:,di])\n",
    "        decoder_input = target_tensor[0,:,di]\n",
    "#         print(decoder_input)\n",
    "#         print(decoder_output.topk(1))\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(decoder, decoder_optimizer, n_iters, songs_hid, print_every=1000):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        number = iter % len(songs)\n",
    "        target_tensor = torch.LongTensor([songs[number - 1]]).view(1,1,-1)\n",
    "        \n",
    "        loss = train(target_tensor,\n",
    "                     decoder, decoder_optimizer, criterion, songs_hid[number])\n",
    "#         print(\"ok\")\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_hid = []\n",
    "# SOS_token = 2*len(note_cl) + len(time_cl) + len(vel_cl)\n",
    "# for i in range(len(songs)):\n",
    "#     songs_hid.append(torch.FloatTensor([random.random() for _ in range(hid_size)]).view(1,1,hid_size))\n",
    "# classes = SOS_token + 1\n",
    "# decoder = DecoderRNN(hid_size, classes)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters(decoder, decoder_optimizer,  100000, songs_hid, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate(decoder, decoder_hidden):\n",
    "    with torch.no_grad():\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        target_length = 1000\n",
    "        outputs = []\n",
    "        decoder_input = torch.tensor([[SOS_token]])\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            outputs.append(topi[0].item())\n",
    "            decoder_input = torch.tensor([[topi[0].item()]])\n",
    "        return outputs\n",
    "\n",
    "\n",
    "decoder_hidden = torch.FloatTensor([random.random() for _ in range(hid_size)]).view(1,1,-1)\n",
    "print(evaluate(decoder, decoder_hidden))\n",
    "postprocess(evaluate(decoder, decoder_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(songs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\models\\model1'\n",
    "torch.save({\n",
    "                    'model_state_dict': decoder.state_dict(),\n",
    "                    }, path)\n",
    "# print(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
